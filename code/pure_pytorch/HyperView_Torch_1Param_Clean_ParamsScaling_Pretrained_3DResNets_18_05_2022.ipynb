{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "270f1670-a145-441d-85b5-c5896262a5d5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "from glob import glob\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "import timm\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.utils.data.dataset import random_split\n",
    "from torch import nn, optim\n",
    "from torch.nn import functional as F\n",
    "from torchvision import transforms\n",
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "from math import ceil\n",
    "from tqdm.notebook import tqdm\n",
    "import wandb\n",
    "from torch_lr_finder import LRFinder\n",
    "from utils import EarlyStopping\n",
    "import utils\n",
    "import plotly.express as px"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "707e7a39-1543-4071-b32f-f03261397be1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy import ndimage\n",
    "from pickle import load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1382c3cd-4290-4b7f-806f-198920a1f686",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mjcharyton\u001b[0m (use `wandb login --relogin` to force relogin)\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: wandb version 0.12.16 is available!  To upgrade, please run:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  $ pip install wandb --upgrade\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                    Syncing run <strong><a href=\"https://wandb.ai/jcharyton/HyperView-initial/runs/qustxfzg\" target=\"_blank\">stellar-valley-51</a></strong> to <a href=\"https://wandb.ai/jcharyton/HyperView-initial\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">docs</a>).<br/>\n",
       "\n",
       "                "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "run = wandb.init(project='HyperView-initial', reinit=True)\n",
    "# wandb.init(mode=\"disabled\") # in case of testing code"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bdc45bc9-94ce-41f5-8e9a-dee4ce53beca",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Paths definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "31f3113b-e082-4f61-ae37-e02b0ec9e990",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data_directory = r'../../train_data'\n",
    "test_data_directory = r'../../test_data'\n",
    "saved_models_directory = r'../../saved_models'\n",
    "submissions_directory = r'../../submissions'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f80dc9fe-75d0-4297-b2fe-e50637b59d2b",
   "metadata": {},
   "source": [
    "### Load mean and std values of training dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d936e375-5279-40c8-90f3-83bdca3a4ff1",
   "metadata": {},
   "outputs": [],
   "source": [
    "means_stds_arrays = np.load(os.path.join(\n",
    "    train_data_directory, 'means_stds_values_training_data.npz'))\n",
    "means = np.array(means_stds_arrays['means'])\n",
    "stds = np.array(means_stds_arrays['stds'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7384d28d-3b5e-4de0-8c00-2771d5dda519",
   "metadata": {},
   "source": [
    "### Load scalers for parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "58b11e80-89f5-4a5f-9530-2ea09cdb2ef9",
   "metadata": {},
   "outputs": [],
   "source": [
    "parameters_scalers = dict()\n",
    "parameters_scalers['P'] = load((open(os.path.join(train_data_directory, 'standard_scaler_P.pkl'), 'rb')))\n",
    "parameters_scalers['K'] = load((open(os.path.join(train_data_directory, 'standard_scaler_K.pkl'), 'rb')))\n",
    "parameters_scalers['Mg'] = load((open(os.path.join(train_data_directory, 'standard_scaler_Mg.pkl'), 'rb')))\n",
    "parameters_scalers['pH'] = load((open(os.path.join(train_data_directory, 'standard_scaler_pH.pkl'), 'rb')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "bdf66e15-7a25-46b8-bd5a-a3fd331e8390",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([70.30265589])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "parameters_scalers['P'].mean_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69734912-1875-401f-9e0b-7afa7eac153e",
   "metadata": {},
   "source": [
    "### Dataset definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "55fc5b6c-09e5-49d5-9211-32d95db7fa30",
   "metadata": {},
   "outputs": [],
   "source": [
    "class HyperViewDataset(Dataset):\n",
    "    def __init__(self, gt_file, img_dir, transform=True, means=None, stds=None, train_transforms=False, parameters_scalers=None):\n",
    "        self.img_dir = img_dir\n",
    "        if gt_file is not None:\n",
    "            self.gt = pd.read_csv(gt_file)[['sample_index', 'P', 'K', 'Mg', 'pH']]\n",
    "        else:\n",
    "            self.gt = None\n",
    "        self.transform = transform  # whether to perform transformation of input data\n",
    "        # whether to perform transformations like on training data\n",
    "        self.train_transforms = train_transforms\n",
    "\n",
    "        if self.train_transforms:\n",
    "            self.training_transforms_composition = transforms.Compose([\n",
    "                transforms.RandomHorizontalFlip(p=0.4), transforms.RandomVerticalFlip(p=0.4)])\n",
    "\n",
    "        self.means = means  # mean values for every band used to normalize data\n",
    "        self.stds = stds  # std values for every band used to normalize data\n",
    "\n",
    "        self.img_files = np.array(\n",
    "            sorted(\n",
    "                glob(os.path.join(img_dir, \"*.npz\")),\n",
    "                key=lambda x: int(os.path.basename(x).replace(\".npz\", \"\")),\n",
    "            )\n",
    "        )\n",
    "\n",
    "        if parameters_scalers is not None:\n",
    "            self.scaler_P = parameters_scalers['P']\n",
    "            self.scaler_K = parameters_scalers['K']\n",
    "            self.scaler_Mg = parameters_scalers['Mg']\n",
    "            self.scaler_pH = parameters_scalers['pH']\n",
    "        else:\n",
    "            self.scaler_P = None\n",
    "            self.scaler_K = None\n",
    "            self.scaler_Mg = None\n",
    "            self.scaler_pH = None\n",
    "\n",
    "    def pad_to_minimum_size(self, min_size, image):\n",
    "        # pads numpy array to defined in `min_size` minimum size of array (w, h)\n",
    "        c, h, w = image.shape\n",
    "        h_diff = (min_size - h)/2\n",
    "        w_diff = (min_size - w)/2\n",
    "\n",
    "        if not h_diff.is_integer():\n",
    "            h_pad1 = int(h_diff - 0.5)\n",
    "            h_pad2 = int(h_diff + 0.5)\n",
    "        else:\n",
    "            h_pad1 = h_pad2 = int(h_diff)\n",
    "\n",
    "        if not w_diff.is_integer():\n",
    "            w_pad1 = int(w_diff - 0.5)\n",
    "            w_pad2 = int(w_diff + 0.5)\n",
    "        else:\n",
    "            w_pad1 = w_pad2 = int(w_diff)\n",
    "\n",
    "        # check if any padding is bigger than zero\n",
    "        if h_pad1+h_pad2+w_pad1+h_pad2 == 0:\n",
    "            return image\n",
    "        else:\n",
    "            return transforms.functional.pad(image, (w_pad1, h_pad1, w_pad2, h_pad2), fill=0)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.img_files)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        # load hyperspectral image to array\n",
    "        img_arr = np.ma.MaskedArray(**np.load(self.img_files[idx]))\n",
    "        img_tensor = torch.as_tensor(img_arr.data, dtype=torch.float)\n",
    "        # Inverting mask is necessary due to masking method in numpy\n",
    "        img_tensor_mask = ~torch.as_tensor(img_arr.mask)\n",
    "        img_masked_tensor = torch.mul(img_tensor, img_tensor_mask)\n",
    "\n",
    "        if self.transform:\n",
    "            img_masked_tensor_transformed = transforms.functional.normalize(\n",
    "                img_masked_tensor, mean=self.means.tolist(), std=self.stds.tolist())\n",
    "            img_masked_tensor_transformed = self.pad_to_minimum_size(\n",
    "                300, img_masked_tensor_transformed)\n",
    "            if self.train_transforms:\n",
    "                img_masked_tensor_transformed = self.training_transforms_composition(\n",
    "                    img_masked_tensor_transformed)\n",
    "            img_result_tensor = img_masked_tensor_transformed\n",
    "        else:\n",
    "            img_result_tensor = img_masked_tensor\n",
    "        # Add dimension at position 1 (depth) to be able to pass it into Conv3D which expects batch_size x channels x depth x height x width\n",
    "        img_result_tensor = torch.unsqueeze(img_result_tensor, dim=1)\n",
    "        \n",
    "        # load labels\n",
    "        if self.gt is not None:\n",
    "            P_gt = self.gt.loc[idx, 'P']\n",
    "            K_gt = self.gt.loc[idx, 'K']\n",
    "            Mg_gt = self.gt.loc[idx, 'Mg']\n",
    "            pH_gt = self.gt.loc[idx, 'pH']\n",
    "            sample_index = self.gt.loc[idx, 'sample_index']\n",
    "            \n",
    "            if self.scaler_P is not None:\n",
    "                assert self.scaler_K is not None\n",
    "                assert self.scaler_Mg is not None\n",
    "                assert self.scaler_pH is not None\n",
    "                \n",
    "                P_gt = self.scaler_P.transform(np.array(P_gt).reshape(1, -1))[0][0]\n",
    "                K_gt = self.scaler_K.transform(np.array(K_gt).reshape(1, -1))[0][0]\n",
    "                Mg_gt = self.scaler_Mg.transform(np.array(Mg_gt).reshape(1, -1))[0][0]\n",
    "                pH_gt = self.scaler_pH.transform(np.array(pH_gt).reshape(1, -1))[0][0]\n",
    "                \n",
    "\n",
    "            sample = {'image': img_result_tensor, 'P': P_gt,\n",
    "                      'K': K_gt, 'Mg': Mg_gt, 'pH': pH_gt, 'sample_index': sample_index}\n",
    "        else:\n",
    "            sample = {'image': img_result_tensor}\n",
    "\n",
    "        return sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "29db8b86-b4a4-4f29-bea0-f51a2c824031",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_data_whole = HyperViewDataset(os.path.join(train_data_directory, 'train_gt.csv'), os.path.join(\n",
    "    train_data_directory, 'train_data'), True, means, stds, train_transforms=True, parameters_scalers=parameters_scalers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "82ad2317-a57a-4b6c-831f-b5c2ed7280cc",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_dataset, validation_dataset = random_split(train_data_whole, [1000, 732], generator=torch.Generator().manual_seed(22))\n",
    "# train_dataset = torch.utils.data.Subset(train_data_whole, list(range(0, 1400)))\n",
    "# validation_dataset = torch.utils.data.Subset(train_data_whole, list(range(1400, len(train_data_whole))))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab1cda9a-39f3-4b58-aea8-79c8dfccf9b1",
   "metadata": {},
   "source": [
    "### Model Definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7722e05c-848f-4114-b6c0-bb718c705e9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchvision\n",
    "from torchvision import datasets, models, transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d148a100-6ad0-439f-a8bc-9ccbdd091852",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda', index=0)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "4320d9a1-a6c4-44a5-a5c4-8f9bd8b69e1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Res3DNetCNN(nn.Module):\n",
    "    def __init__(self, pretrained):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.resnet_model = models.video.r3d_18()\n",
    "\n",
    "        self.resnet_model.stem[0] = nn.Conv3d(150, 64, kernel_size=(3, 7, 7), stride=(1, 2, 2), padding=(1, 3, 3), bias=False)\n",
    "        self.resnet_model.fc = nn.Linear(in_features=512, out_features=1, bias=True)\n",
    "        \n",
    "        if pretrained:\n",
    "            #Download weights for resnet50\n",
    "            url = \"https://download.pytorch.org/models/r3d_18-b3b3357e.pth\"\n",
    "            state = torch.utils.model_zoo.load_url(url)\n",
    "            # state_resnet = {f'resnet_model.{k}': v for k, v in state.items()}\n",
    "            state_resnet = state\n",
    "            # Adapt last layer (FC) to 1 class output\n",
    "            state_resnet['fc.weight'] = state_resnet['fc.weight'][:1, :]\n",
    "            state_resnet['fc.bias'] = state_resnet['fc.bias'][:1]\n",
    "            # Adapt stem.0.weight (Conv3D) layer to 150 input channels\n",
    "            conv1_weight = state_resnet['stem.0.weight']\n",
    "            conv1_dtype = conv1_weight.dtype\n",
    "            conv1_weight = conv1_weight.float()\n",
    "            repeat = int(ceil(150 / 3))\n",
    "            conv1_weight = conv1_weight.repeat(1, repeat, 1, 1, 1)[:, :150, :, :, :] # copy first 3 channels repeat-times\n",
    "            conv1_weight *= (3 / float(150))\n",
    "            conv1_weight = conv1_weight.to(conv1_dtype)\n",
    "            state_resnet['stem.0.weight'] = conv1_weight\n",
    "            \n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.resnet_model(x)\n",
    "#         return {'P': x[0], 'K': x[1], 'Mg': x[2], 'pH': x[3]}\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "2cb2cae6-e7ec-4206-9451-14ee6ae07475",
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 12\n",
    "EPOCHS = 300"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "9c45de25-2011-4cca-8a1c-a6d30848926d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_dataloader = DataLoader(\n",
    "    train_dataset, batch_size=BATCH_SIZE, pin_memory=True, drop_last=True, num_workers=4, shuffle=True)\n",
    "validation_dataloader = DataLoader(\n",
    "    validation_dataset, batch_size=BATCH_SIZE, pin_memory=True, drop_last=True, num_workers=4, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "c11853a9-c192-41f7-88e6-c395fe27016d",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Res3DNetCNN(\n",
       "  (resnet_model): VideoResNet(\n",
       "    (stem): BasicStem(\n",
       "      (0): Conv3d(150, 64, kernel_size=(3, 7, 7), stride=(1, 2, 2), padding=(1, 3, 3), bias=False)\n",
       "      (1): BatchNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (2): ReLU(inplace=True)\n",
       "    )\n",
       "    (layer1): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Sequential(\n",
       "          (0): Conv3DSimple(64, 64, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
       "          (1): BatchNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU(inplace=True)\n",
       "        )\n",
       "        (conv2): Sequential(\n",
       "          (0): Conv3DSimple(64, 64, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
       "          (1): BatchNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Sequential(\n",
       "          (0): Conv3DSimple(64, 64, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
       "          (1): BatchNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU(inplace=True)\n",
       "        )\n",
       "        (conv2): Sequential(\n",
       "          (0): Conv3DSimple(64, 64, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
       "          (1): BatchNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "    )\n",
       "    (layer2): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Sequential(\n",
       "          (0): Conv3DSimple(64, 128, kernel_size=(3, 3, 3), stride=(2, 2, 2), padding=(1, 1, 1), bias=False)\n",
       "          (1): BatchNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU(inplace=True)\n",
       "        )\n",
       "        (conv2): Sequential(\n",
       "          (0): Conv3DSimple(128, 128, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
       "          (1): BatchNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv3d(64, 128, kernel_size=(1, 1, 1), stride=(2, 2, 2), bias=False)\n",
       "          (1): BatchNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Sequential(\n",
       "          (0): Conv3DSimple(128, 128, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
       "          (1): BatchNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU(inplace=True)\n",
       "        )\n",
       "        (conv2): Sequential(\n",
       "          (0): Conv3DSimple(128, 128, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
       "          (1): BatchNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "    )\n",
       "    (layer3): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Sequential(\n",
       "          (0): Conv3DSimple(128, 256, kernel_size=(3, 3, 3), stride=(2, 2, 2), padding=(1, 1, 1), bias=False)\n",
       "          (1): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU(inplace=True)\n",
       "        )\n",
       "        (conv2): Sequential(\n",
       "          (0): Conv3DSimple(256, 256, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
       "          (1): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv3d(128, 256, kernel_size=(1, 1, 1), stride=(2, 2, 2), bias=False)\n",
       "          (1): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Sequential(\n",
       "          (0): Conv3DSimple(256, 256, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
       "          (1): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU(inplace=True)\n",
       "        )\n",
       "        (conv2): Sequential(\n",
       "          (0): Conv3DSimple(256, 256, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
       "          (1): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "    )\n",
       "    (layer4): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Sequential(\n",
       "          (0): Conv3DSimple(256, 512, kernel_size=(3, 3, 3), stride=(2, 2, 2), padding=(1, 1, 1), bias=False)\n",
       "          (1): BatchNorm3d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU(inplace=True)\n",
       "        )\n",
       "        (conv2): Sequential(\n",
       "          (0): Conv3DSimple(512, 512, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
       "          (1): BatchNorm3d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv3d(256, 512, kernel_size=(1, 1, 1), stride=(2, 2, 2), bias=False)\n",
       "          (1): BatchNorm3d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Sequential(\n",
       "          (0): Conv3DSimple(512, 512, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
       "          (1): BatchNorm3d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU(inplace=True)\n",
       "        )\n",
       "        (conv2): Sequential(\n",
       "          (0): Conv3DSimple(512, 512, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
       "          (1): BatchNorm3d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "    )\n",
       "    (avgpool): AdaptiveAvgPool3d(output_size=(1, 1, 1))\n",
       "    (fc): Linear(in_features=512, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = Res3DNetCNN(pretrained=True)\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59468f38-f2cd-486a-95ae-82fcbaeff5b1",
   "metadata": {},
   "source": [
    "### Tests and Overfitting"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "353c9f56-a59f-4905-a7fc-2cdac8b0e2a9",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Overfitting on single batch of data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "fb084d82-5c85-436d-a6c1-6ab9f6aaeba2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "loss_func = torch.nn.L1Loss()\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "1eafdd63-d6b9-4679-8187-d1a250e891c2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_data_single_batch = next(iter(train_dataloader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "ba86b93f-c9d6-4f73-85d8-a4c59bca8a34",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([150, 1, 300, 300])"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data_single_batch['image'][0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "01c79313-617a-433d-8e65-791860a94fca",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([12, 150, 1, 300, 300])"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data_single_batch['image'].to(device, dtype=torch.float).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "afb827c4-e425-4615-baf6-fa04334606ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "output = model(train_data_single_batch['image'].to(device, dtype=torch.float))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "016cc045-9e91-436b-a941-39e4a7d8751b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([12, 1])"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "fcb5194b-adb2-44d2-87a2-348f36a68a0e",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.5715],\n",
       "        [0.3078],\n",
       "        [0.3641],\n",
       "        [0.4050],\n",
       "        [0.3146],\n",
       "        [0.5244],\n",
       "        [0.3135],\n",
       "        [0.3303],\n",
       "        [0.3460],\n",
       "        [0.5116],\n",
       "        [0.3460],\n",
       "        [0.6471]], device='cuda:0', grad_fn=<AddmmBackward0>)"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "9bea7e80-5f45-4a7a-8def-ee8b17eec38e",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.0204],\n",
       "        [ 1.1424],\n",
       "        [-0.6375],\n",
       "        [-0.5256],\n",
       "        [ 0.4508],\n",
       "        [-0.3730],\n",
       "        [ 0.4406],\n",
       "        [ 0.0542],\n",
       "        [ 0.0033],\n",
       "        [-0.0950],\n",
       "        [ 0.2440],\n",
       "        [ 0.1932]], device='cuda:0', dtype=torch.float64)"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stacked_gt = train_data_single_batch['P'].unsqueeze(dim=0).permute(1, 0).to(device)\n",
    "stacked_gt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "2c5097e6-635d-4bcf-86a2-d91ed9af8a1d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.5251, device='cuda:0', grad_fn=<L1LossBackward0>)"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss_func(output, stacked_gt)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e62ac32-ee02-4fed-a9b2-59edec180d54",
   "metadata": {},
   "source": [
    "#### Sprawdzenie czy inwersja skalowania działa właściwie"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "80466e52-40a1-4268-97b6-8bbdfd7d7b12",
   "metadata": {},
   "outputs": [],
   "source": [
    "gt_df = pd.read_csv(os.path.join(train_data_directory, 'train_gt.csv'))[\n",
    "    ['sample_index', 'P', 'K', 'Mg', 'pH']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "6476d6a5-a36f-47bb-a70e-871804d08190",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1406,  461,  780, 1457,  437, 1228,  438, 1708,  921, 1544, 1011, 1318])"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data_single_batch['sample_index']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "83d51d05-29ee-4d2e-83b8-4a0cdcae219f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 69.7],\n",
       "       [104. ],\n",
       "       [ 51.5],\n",
       "       [ 54.8],\n",
       "       [ 83.6],\n",
       "       [ 59.3],\n",
       "       [ 83.3],\n",
       "       [ 71.9],\n",
       "       [ 70.4],\n",
       "       [ 67.5],\n",
       "       [ 77.5],\n",
       "       [ 76. ]])"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gt_df.loc[train_data_single_batch['sample_index'], 'P'].values.reshape(-1, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "be38d5c2-fb8f-43aa-a309-e7757bf6afb9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "StandardScaler()"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scaler = getattr(train_dataset.dataset, f'scaler_P')\n",
    "scaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "51b432ef-770c-413d-8f96-aa0b36e72edc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 69.7],\n",
       "       [104. ],\n",
       "       [ 51.5],\n",
       "       [ 54.8],\n",
       "       [ 83.6],\n",
       "       [ 59.3],\n",
       "       [ 83.3],\n",
       "       [ 71.9],\n",
       "       [ 70.4],\n",
       "       [ 67.5],\n",
       "       [ 77.5],\n",
       "       [ 76. ]])"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scaler.inverse_transform(stacked_gt.cpu())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "365cecc0-6574-496f-83ef-bd705cb34e36",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True]])"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scaler.inverse_transform(stacked_gt.cpu()) == gt_df.loc[train_data_single_batch['sample_index'], 'P'].values.reshape(-1, 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2774a59-0fff-48f7-aa1b-783f8b2317a8",
   "metadata": {},
   "source": [
    "#### Właściwa pętla overfit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "7bb27059-c42c-49b1-b1eb-a44a6a16b773",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 0, loss: 0.42281049489974976, MSE: [0.42281047], MSE from unscaled values: [367.85767]\n",
      "epoch: 10, loss: 0.9767284393310547, MSE: [0.9767285], MSE from unscaled values: [849.7829]\n",
      "epoch: 20, loss: 0.25168749690055847, MSE: [0.2516875], MSE from unscaled values: [218.97559]\n",
      "epoch: 30, loss: 0.13768121600151062, MSE: [0.13768122], MSE from unscaled values: [119.78674]\n",
      "epoch: 40, loss: 0.06927946209907532, MSE: [0.06927945], MSE from unscaled values: [60.27518]\n",
      "epoch: 50, loss: 0.044809740036726, MSE: [0.04480973], MSE from unscaled values: [38.985813]\n",
      "epoch: 60, loss: 0.019443942233920097, MSE: [0.01944394], MSE from unscaled values: [16.916807]\n",
      "epoch: 70, loss: 0.008407908491790295, MSE: [0.00840791], MSE from unscaled values: [7.3151336]\n",
      "epoch: 80, loss: 0.011573085561394691, MSE: [0.01157308], MSE from unscaled values: [10.068933]\n",
      "epoch: 90, loss: 0.004000367596745491, MSE: [0.00400037], MSE from unscaled values: [3.4804327]\n",
      "epoch: 100, loss: 0.0009780051186680794, MSE: [0.00097801], MSE from unscaled values: [0.850892]\n",
      "epoch: 110, loss: 0.0003874878166243434, MSE: [0.00038749], MSE from unscaled values: [0.33712617]\n",
      "epoch: 120, loss: 0.00011679948511300609, MSE: [0.0001168], MSE from unscaled values: [0.10161924]\n",
      "epoch: 130, loss: 3.155133526888676e-05, MSE: [3.1551335e-05], MSE from unscaled values: [0.02745034]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-90-6a12ab9aec8c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     19\u001b[0m     \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 21\u001b[0;31m     \u001b[0moutput_cpu\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moutput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdetach\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcpu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     22\u001b[0m     \u001b[0mstacked_gt_cpu\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstacked_gt_device\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcpu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "img_data_device = train_data_single_batch['image'].to(\n",
    "    device, dtype=torch.float)\n",
    "stacked_gt_device = train_data_single_batch['P'].unsqueeze(dim=0).permute(1, 0).to(device, dtype=torch.float)\n",
    "scaler = getattr(train_dataset.dataset, f'scaler_P')\n",
    "\n",
    "model = Res3DNetCNN(pretrained=True).to(device)\n",
    "\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=0.01)\n",
    "loss_func = torch.nn.MSELoss()\n",
    "model.train()\n",
    "\n",
    "for epoch in range(301):\n",
    "\n",
    "    output = model(img_data_device)\n",
    "    loss = loss_func(output, stacked_gt_device)\n",
    "\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "    output_cpu = output.detach().cpu().numpy()\n",
    "    stacked_gt_cpu = stacked_gt_device.cpu().numpy()\n",
    "    \n",
    "    output_cpu_inversed = scaler.inverse_transform(output_cpu)\n",
    "    stacked_gt_cpu_inversed = scaler.inverse_transform(stacked_gt_cpu)\n",
    "\n",
    "    # Calculate MSE for each class\n",
    "    mse_inversed = np.mean((stacked_gt_cpu_inversed - output_cpu_inversed) ** 2, axis=0)\n",
    "    mse = np.mean((stacked_gt_cpu - output_cpu) ** 2, axis=0)\n",
    "\n",
    "    if epoch % 10 == 0:\n",
    "        print(f'epoch: {epoch}, loss: {loss.data.cpu().numpy()}, MSE: {mse}, MSE from unscaled values: {mse_inversed}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f7e821b-ba10-45f2-b8c8-62e1b57816b1",
   "metadata": {},
   "source": [
    "### Training Definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "c71e05fd-b851-4200-8350-e03731ecc589",
   "metadata": {},
   "outputs": [],
   "source": [
    "parameter = 'pH'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "480520a1-ca1c-422f-b520-dce7190e6048",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'checkpoint_state_dict_Res3DNet18_18_05_2022_Single_Parameter_Scaled_PretrainedModel_pH'"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "save_name = \"checkpoint_state_dict_Res3DNet18_18_05_2022_Single_Parameter_Scaled_PretrainedModel_{}\".format(parameter)\n",
    "save_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "a11e1370-4315-4af1-b61a-477d036d6486",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = save_name+'.pth'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "0bd5be2e-f408-44b5-990e-f00b80f5a61a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# save subsets indices to text files\n",
    "np.array(train_dataset.indices).tofile(os.path.join(saved_models_directory, 'DataSubsets_indices', save_name+'_train_indices.txt'), sep='|')\n",
    "np.array(validation_dataset.indices).tofile(os.path.join(saved_models_directory, 'DataSubsets_indices', save_name+'_validation_indices.txt'), sep='|')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "558c42af-2b45-41f3-9184-577eb2830eea",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Res3DNetCNN(pretrained=True).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "634f4c5f-77f4-4139-8df0-7a0dbdf555b8",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wandb.watch(model, log=\"None\", log_freq=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "ea978104-75da-4a8c-a865-f5ac6c696d67",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = torch.optim.AdamW(model.parameters(), lr=0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "3fda57be-f914-4822-b681-f613ba7b11b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_func = torch.nn.MSELoss()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10d1d174-8dce-42c6-9d24-40956ff633ac",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### Find LR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "868b12f9-7a9f-4514-ad13-c91ead27cdc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch_lr_finder.lr_finder import TrainDataLoaderIter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "f0447003-dd8c-4a13-a349-f9476ccf5a66",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomTrainIter(TrainDataLoaderIter):\n",
    "    def inputs_labels_from_batch(self, batch_data):\n",
    "        return (torch.as_tensor(batch_data['image'], dtype=torch.float),\n",
    "                torch.as_tensor(batch_data['P'].unsqueeze(dim=0).permute(1, 0), dtype=torch.float))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "eb184931-2a07-41b4-a17c-b35f8bcc16f3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "89e1e8b7fe794baa9e0d2a7abbd03313",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stopping early, the loss has diverged\n",
      "Learning rate search finished. See the graph with {finder_name}.plot()\n"
     ]
    }
   ],
   "source": [
    "lr_finder = LRFinder(model, optimizer, loss_func, device=device)\n",
    "lr_finder.range_test(CustomTrainIter(train_dataloader),\n",
    "                     start_lr=0.00001, end_lr=100, num_iter=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "647f2f4e-d144-485d-92b3-b1e7914ab310",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LR suggestion: steepest gradient\n",
      "Suggested LR: 2.06E-01\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "lr_finder.plot()\n",
    "lr_finder.reset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "ee758767-7e7c-410b-92a3-1b0b719a392c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.206"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "2.06E-01"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "257faf31-7f43-406f-a382-d997f0bb5cb6",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "ea4809cc-4fe1-4db7-9ade-872ce437a65d",
   "metadata": {},
   "outputs": [],
   "source": [
    "patience_scheduler_overfit = 5\n",
    "scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer=optimizer, mode='min',\n",
    "                                                       factor=0.6, patience=patience_scheduler_overfit,\n",
    "                                                       threshold=0.0001, threshold_mode='abs')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "496f6681-41b1-4382-9b15-34ef4c69e670",
   "metadata": {},
   "outputs": [],
   "source": [
    "early_stopping = utils.EarlyStopping(patience=(2*patience_scheduler_overfit)+3, verbose=True,\n",
    "                                     path=os.path.join(saved_models_directory, 'checkpoint_state_dict.pth'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3975113-0cc1-4ca4-b515-8d29bc9407d7",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### Logging training informations for W&B"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "d7afd373-eeb3-4e78-9bc0-51be9fded852",
   "metadata": {},
   "outputs": [],
   "source": [
    "config = wandb.config\n",
    "config.model = 'ResNet3D 18 layer'\n",
    "config.optimizer = 'AdamW'\n",
    "config.loss_function = 'MSELoss'\n",
    "config.learning_rate_start = optimizer.param_groups[0][\"lr\"]\n",
    "# config.momentum = optimizer.param_groups[0][\"momentum\"]\n",
    "config.momentum = None\n",
    "config.weight_decay = optimizer.param_groups[0][\"weight_decay\"]\n",
    "config.scheduler = 'ReduceLROnPlateau'\n",
    "config.scheduler_factor = 0.6\n",
    "config.scheduler_patience = 5\n",
    "config.scheduler_threshold = 0.0001\n",
    "config.batch_size = BATCH_SIZE\n",
    "config.notes = 'ResNet3D 18 layer Parameter {} SCALED Training split:1000, Validation: 732. Scaled predicted variable. Model pretrained on KINETICS400_V1'.format(parameter)\n",
    "config.parameter = parameter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "6a22f51e-eb05-466e-9632-4ddfba9d6ad6",
   "metadata": {},
   "outputs": [],
   "source": [
    "previous_epochs = 0  # how many epochs have been done previously if resuming"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "7233ac28-6fdf-42e7-99e8-8843964e15c6",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "epoch 0 training data:   0%|          | 0/83 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 0, LR: 0.01, train loss: 2.180542230606079, train MSE: [2.180542230606079], train MSE from unscaled values: [0.147657573223114]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "epoch 0 validation data:   0%|          | 0/61 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 0, validation loss: 0.9404950737953186, validation MSE: [0.9404950737953186], validation MSE from unscaled values: [0.0636865571141243]\n",
      "Validation loss decreased (inf --> 0.940495).  Saving model ...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "epoch 1 training data:   0%|          | 0/83 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 1, LR: 0.01, train loss: 0.9196508526802063, train MSE: [0.9196509718894958], train MSE from unscaled values: [0.062275078147649765]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "epoch 1 validation data:   0%|          | 0/61 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 1, validation loss: 1.2300941944122314, validation MSE: [1.230094313621521], validation MSE from unscaled values: [0.08329705148935318]\n",
      "EarlyStopping counter: 1 out of 13\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "epoch 2 training data:   0%|          | 0/83 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 2, LR: 0.01, train loss: 0.9239451289176941, train MSE: [0.9239450693130493], train MSE from unscaled values: [0.0625658705830574]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "epoch 2 validation data:   0%|          | 0/61 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 2, validation loss: 0.9254891276359558, validation MSE: [0.9254891872406006], validation MSE from unscaled values: [0.06267042458057404]\n",
      "Validation loss decreased (0.940495 --> 0.925489).  Saving model ...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "epoch 3 training data:   0%|          | 0/83 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 3, LR: 0.01, train loss: 0.9371595978736877, train MSE: [0.9371595978736877], train MSE from unscaled values: [0.06346069276332855]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "epoch 3 validation data:   0%|          | 0/61 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 3, validation loss: 0.9522306323051453, validation MSE: [0.9522306323051453], validation MSE from unscaled values: [0.06448124349117279]\n",
      "EarlyStopping counter: 1 out of 13\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "epoch 4 training data:   0%|          | 0/83 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 4, LR: 0.01, train loss: 0.9212562441825867, train MSE: [0.9212563037872314], train MSE from unscaled values: [0.062383782118558884]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "epoch 4 validation data:   0%|          | 0/61 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 4, validation loss: 0.9280498623847961, validation MSE: [0.9280499219894409], validation MSE from unscaled values: [0.06284382194280624]\n",
      "EarlyStopping counter: 2 out of 13\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "epoch 5 training data:   0%|          | 0/83 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 5, LR: 0.01, train loss: 0.9220159649848938, train MSE: [0.9220160245895386], train MSE from unscaled values: [0.06243523210287094]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "epoch 5 validation data:   0%|          | 0/61 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 5, validation loss: 1.9093934297561646, validation MSE: [1.9093936681747437], validation MSE from unscaled values: [0.12929648160934448]\n",
      "EarlyStopping counter: 3 out of 13\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "epoch 6 training data:   0%|          | 0/83 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 6, LR: 0.01, train loss: 0.933747410774231, train MSE: [0.9337474703788757], train MSE from unscaled values: [0.06322963535785675]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "epoch 6 validation data:   0%|          | 0/61 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 6, validation loss: 0.9454857707023621, validation MSE: [0.9454857110977173], validation MSE from unscaled values: [0.06402450799942017]\n",
      "EarlyStopping counter: 4 out of 13\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "epoch 7 training data:   0%|          | 0/83 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 7, LR: 0.01, train loss: 0.9129167795181274, train MSE: [0.9129167795181274], train MSE from unscaled values: [0.06181906536221504]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "epoch 7 validation data:   0%|          | 0/61 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 7, validation loss: 0.9292100667953491, validation MSE: [0.9292101263999939], validation MSE from unscaled values: [0.06292238086462021]\n",
      "EarlyStopping counter: 5 out of 13\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "epoch 8 training data:   0%|          | 0/83 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 8, LR: 0.01, train loss: 0.9037896990776062, train MSE: [0.9037896394729614], train MSE from unscaled values: [0.06120101362466812]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "epoch 8 validation data:   0%|          | 0/61 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 8, validation loss: 0.9892203211784363, validation MSE: [0.9892202615737915], validation MSE from unscaled values: [0.06698604673147202]\n",
      "EarlyStopping counter: 6 out of 13\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "epoch 9 training data:   0%|          | 0/83 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 9, LR: 0.006, train loss: 0.8907052874565125, train MSE: [0.8907053470611572], train MSE from unscaled values: [0.060315005481243134]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "epoch 9 validation data:   0%|          | 0/61 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 9, validation loss: 0.8970881700515747, validation MSE: [0.8970882296562195], validation MSE from unscaled values: [0.060747213661670685]\n",
      "Validation loss decreased (0.925489 --> 0.897088).  Saving model ...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "epoch 10 training data:   0%|          | 0/83 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 10, LR: 0.006, train loss: 0.8971047401428223, train MSE: [0.8971046805381775], train MSE from unscaled values: [0.06074834242463112]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "epoch 10 validation data:   0%|          | 0/61 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 10, validation loss: 0.939528226852417, validation MSE: [0.9395282864570618], validation MSE from unscaled values: [0.06362110376358032]\n",
      "EarlyStopping counter: 1 out of 13\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "epoch 11 training data:   0%|          | 0/83 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 11, LR: 0.006, train loss: 0.9152135848999023, train MSE: [0.9152137041091919], train MSE from unscaled values: [0.061974599957466125]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "epoch 11 validation data:   0%|          | 0/61 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 11, validation loss: 0.8998606204986572, validation MSE: [0.8998607397079468], validation MSE from unscaled values: [0.06093495711684227]\n",
      "EarlyStopping counter: 2 out of 13\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "epoch 12 training data:   0%|          | 0/83 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 12, LR: 0.006, train loss: 0.8997015357017517, train MSE: [0.8997014760971069], train MSE from unscaled values: [0.06092417985200882]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "epoch 12 validation data:   0%|          | 0/61 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 12, validation loss: 0.9185136556625366, validation MSE: [0.9185137152671814], validation MSE from unscaled values: [0.06219806894659996]\n",
      "EarlyStopping counter: 3 out of 13\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "epoch 13 training data:   0%|          | 0/83 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 13, LR: 0.006, train loss: 0.8958949446678162, train MSE: [0.8958950042724609], train MSE from unscaled values: [0.060666415840387344]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "epoch 13 validation data:   0%|          | 0/61 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 13, validation loss: 0.9158332943916321, validation MSE: [0.9158332943916321], validation MSE from unscaled values: [0.062016561627388]\n",
      "EarlyStopping counter: 4 out of 13\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "epoch 14 training data:   0%|          | 0/83 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 14, LR: 0.006, train loss: 0.8924917578697205, train MSE: [0.8924918174743652], train MSE from unscaled values: [0.06043596565723419]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "epoch 14 validation data:   0%|          | 0/61 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 14, validation loss: 0.9166811108589172, validation MSE: [0.9166811108589172], validation MSE from unscaled values: [0.062073964625597]\n",
      "EarlyStopping counter: 5 out of 13\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "epoch 15 training data:   0%|          | 0/83 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 15, LR: 0.006, train loss: 0.8888484239578247, train MSE: [0.8888483643531799], train MSE from unscaled values: [0.06018925830721855]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "epoch 15 validation data:   0%|          | 0/61 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 15, validation loss: 0.9161576628684998, validation MSE: [0.9161576628684998], validation MSE from unscaled values: [0.06203852593898773]\n",
      "EarlyStopping counter: 6 out of 13\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "epoch 16 training data:   0%|          | 0/83 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 16, LR: 0.0036, train loss: 0.882690966129303, train MSE: [0.882690966129303], train MSE from unscaled values: [0.059772297739982605]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "epoch 16 validation data:   0%|          | 0/61 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 16, validation loss: 0.9240567088127136, validation MSE: [0.9240566492080688], validation MSE from unscaled values: [0.06257341802120209]\n",
      "EarlyStopping counter: 7 out of 13\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "epoch 17 training data:   0%|          | 0/83 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 17, LR: 0.0036, train loss: 0.8974753618240356, train MSE: [0.8974753022193909], train MSE from unscaled values: [0.06077342852950096]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "epoch 17 validation data:   0%|          | 0/61 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 17, validation loss: 0.9124096035957336, validation MSE: [0.9124096632003784], validation MSE from unscaled values: [0.06178472563624382]\n",
      "EarlyStopping counter: 8 out of 13\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "epoch 18 training data:   0%|          | 0/83 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 18, LR: 0.0036, train loss: 0.8940969705581665, train MSE: [0.8940970301628113], train MSE from unscaled values: [0.060544662177562714]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "epoch 18 validation data:   0%|          | 0/61 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 18, validation loss: 0.915322482585907, validation MSE: [0.9153225421905518], validation MSE from unscaled values: [0.06198197603225708]\n",
      "EarlyStopping counter: 9 out of 13\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "epoch 19 training data:   0%|          | 0/83 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 19, LR: 0.0036, train loss: 0.8735893368721008, train MSE: [0.8735893964767456], train MSE from unscaled values: [0.05915598198771477]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "epoch 19 validation data:   0%|          | 0/61 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 19, validation loss: 0.9058598279953003, validation MSE: [0.9058598279953003], validation MSE from unscaled values: [0.06134120002388954]\n",
      "EarlyStopping counter: 10 out of 13\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "epoch 20 training data:   0%|          | 0/83 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 20, LR: 0.0036, train loss: 0.8682471513748169, train MSE: [0.8682471513748169], train MSE from unscaled values: [0.05879421532154083]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "epoch 20 validation data:   0%|          | 0/61 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 20, validation loss: 0.9177342057228088, validation MSE: [0.9177342653274536], validation MSE from unscaled values: [0.062145281583070755]\n",
      "EarlyStopping counter: 11 out of 13\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "epoch 21 training data:   0%|          | 0/83 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 21, LR: 0.0036, train loss: 0.8889111876487732, train MSE: [0.888911247253418], train MSE from unscaled values: [0.0601935088634491]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "epoch 21 validation data:   0%|          | 0/61 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 21, validation loss: 1.2576695680618286, validation MSE: [1.2576695680618286], validation MSE from unscaled values: [0.08516433835029602]\n",
      "EarlyStopping counter: 12 out of 13\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "epoch 22 training data:   0%|          | 0/83 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 22, LR: 0.00216, train loss: 0.8710095286369324, train MSE: [0.8710094690322876], train MSE from unscaled values: [0.0589812695980072]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "epoch 22 validation data:   0%|          | 0/61 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 22, validation loss: 0.8986175656318665, validation MSE: [0.8986175656318665], validation MSE from unscaled values: [0.060850776731967926]\n",
      "EarlyStopping counter: 13 out of 13\n",
      "Early stopping\n"
     ]
    }
   ],
   "source": [
    "scaler = getattr(train_dataset.dataset, f'scaler_{parameter}')\n",
    "\n",
    "for epoch in range(previous_epochs, EPOCHS+previous_epochs):\n",
    "    # TRAINING Part\n",
    "    model.train()\n",
    "    train_loss = []\n",
    "    mse_train_list = []\n",
    "    mse_inversed_train_list = []\n",
    "\n",
    "    bar = tqdm(train_dataloader, position=0, leave=False,\n",
    "               desc=f'epoch {epoch} training data')\n",
    "    i = 0\n",
    "    for train_data in bar:  # for each training step\n",
    "        i += 1\n",
    "        img_data_device = train_data['image'].to(device, dtype=torch.float)\n",
    "#         stacked_gt_device = torch.stack((train_data['P'], train_data['K'], train_data['Mg'], train_data['pH'])).transpose(\n",
    "#             0, 1).to(device, dtype=torch.float)\n",
    "        stacked_gt_device = train_data[parameter].unsqueeze(dim=0).permute(1, 0).to(device, dtype=torch.float)\n",
    "\n",
    "        output = model(img_data_device)\n",
    "\n",
    "        loss = loss_func(output, stacked_gt_device)\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        train_loss.append(loss)\n",
    "\n",
    "        output_cpu = output.detach().cpu().numpy()\n",
    "        stacked_gt_cpu = stacked_gt_device.cpu().numpy()\n",
    "        \n",
    "        output_cpu_inversed = scaler.inverse_transform(output_cpu)\n",
    "        stacked_gt_cpu_inversed = scaler.inverse_transform(stacked_gt_cpu)\n",
    "\n",
    "        # Calculate MSE for each class\n",
    "        mse = np.mean((stacked_gt_cpu - output_cpu) ** 2, axis=0)\n",
    "        mse_inversed = np.mean((stacked_gt_cpu_inversed - output_cpu_inversed) ** 2, axis=0)\n",
    "        mse_train_list.append(mse)\n",
    "        mse_inversed_train_list.append(mse_inversed)\n",
    "        \n",
    "\n",
    "        if i % 10 == 0:  # log every 10 batches\n",
    "            train_log_dict = dict()\n",
    "            train_log_dict['batch_number'] = i\n",
    "            train_log_dict['epoch'] = epoch\n",
    "            train_log_dict['train_batch_loss'] = loss\n",
    "            train_log_dict['train_batch_MSE_{}'.format(parameter)] = mse[0]\n",
    "            wandb.log(train_log_dict)\n",
    "\n",
    "    avg_train_loss = torch.stack(train_loss).mean().item()\n",
    "    avg_train_mse = torch.as_tensor(\n",
    "        np.array(mse_train_list)).mean(axis=0).numpy().tolist()\n",
    "    avg_train_mse_inversed = torch.as_tensor(\n",
    "        np.array(mse_inversed_train_list)).mean(axis=0).numpy().tolist()\n",
    "\n",
    "    print(\n",
    "        f'epoch: {epoch}, LR: {optimizer.param_groups[0][\"lr\"]}, train loss: {avg_train_loss}, train MSE: {avg_train_mse}, train MSE from unscaled values: {avg_train_mse_inversed}')\n",
    "    wandb.log({'epoch': epoch, 'average_train_loss': avg_train_loss, 'average_train_MSE_{}'.format(parameter): avg_train_mse_inversed[0]})\n",
    "\n",
    "    # VALIDATION Part\n",
    "    model.eval()\n",
    "    val_bar = tqdm(validation_dataloader, position=0,\n",
    "                   leave=False, desc=f'epoch {epoch} validation data')\n",
    "    with torch.no_grad():\n",
    "        val_loss = []\n",
    "        mse_val_list = []\n",
    "        mse_inversed_val_list = []\n",
    "        for val_data in val_bar:\n",
    "            img_data_device = val_data['image'].to(device, dtype=torch.float)\n",
    "#             stacked_gt_device = torch.stack((val_data['P'], val_data['K'], val_data['Mg'], val_data['pH'])).transpose(\n",
    "#                 0, 1).to(device, dtype=torch.float)\n",
    "            stacked_gt_device =  val_data[parameter].unsqueeze(dim=0).permute(1, 0).to(device, dtype=torch.float)\n",
    "\n",
    "            output = model(img_data_device)\n",
    "\n",
    "            loss = loss_func(output, stacked_gt_device)\n",
    "            val_loss.append(loss)\n",
    "\n",
    "            output_cpu = output.detach().cpu().numpy()\n",
    "            stacked_gt_cpu = stacked_gt_device.cpu().numpy()\n",
    "            \n",
    "            output_cpu_inversed = scaler.inverse_transform(output_cpu)\n",
    "            stacked_gt_cpu_inversed = scaler.inverse_transform(stacked_gt_cpu)\n",
    "\n",
    "            # Calculate MSE for each class\n",
    "            mse = np.mean((stacked_gt_cpu - output_cpu) ** 2, axis=0)\n",
    "            mse_val_list.append(mse)\n",
    "            mse_inversed = np.mean((stacked_gt_cpu_inversed - output_cpu_inversed) ** 2, axis=0)\n",
    "            mse_inversed_val_list.append(mse_inversed)\n",
    "\n",
    "\n",
    "        avg_val_loss = torch.stack(val_loss).mean().item()\n",
    "        avg_val_mse = torch.as_tensor(\n",
    "            np.array(mse_val_list)).mean(axis=0).numpy().tolist()\n",
    "        avg_val_mse_inversed = torch.as_tensor(\n",
    "            np.array(mse_inversed_val_list)).mean(axis=0).numpy().tolist()\n",
    "\n",
    "        print(f'epoch: {epoch}, validation loss: {avg_val_loss}, validation MSE: {avg_val_mse}, validation MSE from unscaled values: {avg_val_mse_inversed}')\n",
    "        # using MSE from inversed values in W&B logger to make it compatible with previous runs in W&B\n",
    "        wandb.log({'epoch': epoch, 'average_val_loss': avg_val_loss, 'average_validation_MSE_{}'.format(parameter): avg_val_mse_inversed[0]}) \n",
    "\n",
    "        scheduler.step(avg_val_loss)\n",
    "        # early_stopping needs the validation loss to check if it has decresed,\n",
    "        # and if it has, it will make a checkpoint of the current model\n",
    "        early_stopping(avg_val_loss, model)\n",
    "\n",
    "        if early_stopping.early_stop:\n",
    "            print(\"Early stopping\")\n",
    "            break"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "630df441-d9af-44d6-8816-19e2bcc53e57",
   "metadata": {},
   "source": [
    "#### Saving model state dict and loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "5aaf13cc-2e25-4bdf-822e-3d365964ca6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(), os.path.join(\n",
    "    saved_models_directory, model_name+f'_EPOCHS_{epoch}.pth'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "d6ffb3e2-5cb5-49c2-abfe-5ecaa530087b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# rename checkpoint.pth\n",
    "! mv ../../saved_models/checkpoint_state_dict.pth ../../saved_models/checkpoint_state_dict_Res3DNet18_18_05_2022_Single_Parameter_Scaled_PretrainedModel_pH.pth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "3e4dc5ea-7e3a-4ce5-93e6-e6baf9615149",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# load saved model\n",
    "modelLoad = Res3DNetCNN(False)\n",
    "modelLoad.load_state_dict(torch.load(os.path.join(\n",
    "    saved_models_directory, 'checkpoint_state_dict_Res3DNet18_18_05_2022_Single_Parameter_Scaled_PretrainedModel_pH.pth')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "c1c66db3-7fcf-4410-b51c-ae9706394be0",
   "metadata": {},
   "outputs": [],
   "source": [
    "modelLoad = modelLoad.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24afa999-5283-4d5e-8d16-bb5e2d8876ec",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
